{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata = pd.read_csv('churn_data.csv')\n",
    "cvalid = pd.read_csv('churn_validation.csv')\n",
    "        \n",
    "cdata = pd.get_dummies(cdata, columns=cat_features(cdata))\n",
    "cdata = cdata.drop(['Churn_No'], axis=1)\n",
    "cdata.rename(columns = {'Churn_Yes':'Churn'}, inplace = True)\n",
    "\n",
    "data_x = cdata.drop(['Churn'], axis=1)\n",
    "data_y = cdata['Churn']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                    random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mod = linear_model.LogisticRegression()\n",
    "log_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30739119 0.50113121 0.39115316 0.54526617 0.40375419 0.67087871\n",
      " 0.76927679 0.4982347  0.39268247 0.68448938]\n",
      "[0.69260881 0.49886879 0.60884684 0.45473383 0.59624581 0.32912129\n",
      " 0.23072321 0.5017653  0.60731753 0.31551062]\n"
     ]
    }
   ],
   "source": [
    "# make predictions - class labels and predictive probabilities\n",
    "preds = log_mod.predict(x_test) # class labels\n",
    "pred_probs = log_mod.predict_proba(x_test) # predicted probability 0 and 1 for each test case\n",
    "#print(pred_probs[:10])\n",
    "# [prob being 0 prob being a 1]\n",
    "pred_pos = pred_probs.transpose()[1] # prob of each being a 1\n",
    "pred_neg = pred_probs.transpose()[0] # prob of being a 0\n",
    "print(pred_pos[:10])\n",
    "print(pred_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted      P(1)      P(0)\n",
      "5         0          0  0.307391  0.692609\n",
      "24        1          1  0.501131  0.498869\n",
      "29        1          0  0.391153  0.608847\n",
      "61        1          1  0.545266  0.454734\n",
      "19        0          0  0.403754  0.596246\n",
      "95        1          1  0.670879  0.329121\n",
      "2         1          1  0.769277  0.230723\n",
      "25        0          0  0.498235  0.501765\n",
      "90        0          0  0.392682  0.607318\n",
      "78        1          1  0.684489  0.315511\n",
      "12        0          1  0.678395  0.321605\n",
      "74        0          1  0.868615  0.131385\n",
      "34        1          0  0.410420  0.589580\n",
      "16        1          0  0.248717  0.751283\n",
      "20        0          0  0.476307  0.523693\n",
      "84        0          0  0.247611  0.752389\n",
      "107       0          1  0.685458  0.314542\n",
      "123       0          0  0.449741  0.550259\n",
      "18        1          0  0.447265  0.552735\n",
      "82        1          1  0.844427  0.155573\n"
     ]
    }
   ],
   "source": [
    "# look at the results\n",
    "pred_df = pd.DataFrame({'Actual':y_test, 'Predicted':preds,\n",
    "                        'P(1)':pred_pos, 'P(0)':pred_neg})\n",
    "print(pred_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6410256410256411\n",
      "Precison: 0.7058823529411765\n",
      "Recall: 0.5714285714285714\n",
      "F1: 0.6315789473684211\n",
      "ROC AUC: 0.6468253968253967\n",
      "Confusion Matrix:\n",
      "[[13  5]\n",
      " [ 9 12]]\n"
     ]
    }
   ],
   "source": [
    "print_binary_classif_error_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- EVALING 1 --------\n",
      "Accuracy: 0.5384615384615384\n",
      "Precison: 0.5789473684210527\n",
      "Recall: 0.5238095238095238\n",
      "F1: 0.5500000000000002\n",
      "ROC AUC: 0.5396825396825397\n",
      "Confusion Matrix:\n",
      "[[10  8]\n",
      " [10 11]]\n",
      "------------- EVALING 3 --------\n",
      "Accuracy: 0.46153846153846156\n",
      "Precison: 0.5\n",
      "Recall: 0.5238095238095238\n",
      "F1: 0.5116279069767442\n",
      "ROC AUC: 0.4563492063492063\n",
      "Confusion Matrix:\n",
      "[[ 7 11]\n",
      " [10 11]]\n",
      "------------- EVALING 5 --------\n",
      "Accuracy: 0.5897435897435898\n",
      "Precison: 0.5925925925925926\n",
      "Recall: 0.7619047619047619\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.5753968253968254\n",
      "Confusion Matrix:\n",
      "[[ 7 11]\n",
      " [ 5 16]]\n",
      "------------- EVALING 7 --------\n",
      "Accuracy: 0.46153846153846156\n",
      "Precison: 0.5\n",
      "Recall: 0.5714285714285714\n",
      "F1: 0.5333333333333333\n",
      "ROC AUC: 0.4523809523809524\n",
      "Confusion Matrix:\n",
      "[[ 6 12]\n",
      " [ 9 12]]\n",
      "------------- EVALING 9 --------\n",
      "Accuracy: 0.6666666666666666\n",
      "Precison: 0.6818181818181818\n",
      "Recall: 0.7142857142857143\n",
      "F1: 0.6976744186046512\n",
      "ROC AUC: 0.6626984126984128\n",
      "Confusion Matrix:\n",
      "[[11  7]\n",
      " [ 6 15]]\n",
      "------------- EVALING 11 --------\n",
      "Accuracy: 0.6153846153846154\n",
      "Precison: 0.625\n",
      "Recall: 0.7142857142857143\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.6071428571428572\n",
      "Confusion Matrix:\n",
      "[[ 9  9]\n",
      " [ 6 15]]\n",
      "------------- EVALING 13 --------\n",
      "Accuracy: 0.5897435897435898\n",
      "Precison: 0.5925925925925926\n",
      "Recall: 0.7619047619047619\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.5753968253968254\n",
      "Confusion Matrix:\n",
      "[[ 7 11]\n",
      " [ 5 16]]\n",
      "------------- EVALING 15 --------\n",
      "Accuracy: 0.5641025641025641\n",
      "Precison: 0.5833333333333334\n",
      "Recall: 0.6666666666666666\n",
      "F1: 0.6222222222222222\n",
      "ROC AUC: 0.5555555555555555\n",
      "Confusion Matrix:\n",
      "[[ 8 10]\n",
      " [ 7 14]]\n",
      "------------- EVALING 17 --------\n",
      "Accuracy: 0.6410256410256411\n",
      "Precison: 0.64\n",
      "Recall: 0.7619047619047619\n",
      "F1: 0.6956521739130435\n",
      "ROC AUC: 0.6309523809523809\n",
      "Confusion Matrix:\n",
      "[[ 9  9]\n",
      " [ 5 16]]\n",
      "------------- EVALING 19 --------\n",
      "Accuracy: 0.6153846153846154\n",
      "Precison: 0.625\n",
      "Recall: 0.7142857142857143\n",
      "F1: 0.6666666666666666\n",
      "ROC AUC: 0.6071428571428572\n",
      "Confusion Matrix:\n",
      "[[ 9  9]\n",
      " [ 6 15]]\n",
      "------------- EVALING 21 --------\n",
      "Accuracy: 0.5897435897435898\n",
      "Precison: 0.6086956521739131\n",
      "Recall: 0.6666666666666666\n",
      "F1: 0.6363636363636365\n",
      "ROC AUC: 0.5833333333333333\n",
      "Confusion Matrix:\n",
      "[[ 9  9]\n",
      " [ 7 14]]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                    random_state=4)\n",
    "\n",
    "ks = [1,3,5,7,9,11,13,15,17,19,21] # Possible numbers for K\n",
    "for k in ks:\n",
    "    print('------------- EVALING ' + str(k) + ' --------')\n",
    "    mod = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    mod.fit(x_train, y_train)\n",
    "    \n",
    "    # make preds on current model\n",
    "    preds = mod.predict(x_test)\n",
    "    \n",
    "    print_binary_classif_error_report(y_test, preds)\n",
    "\n",
    "    \n",
    "## A K of Nine is the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Precison: 0.6818181818181818\n",
      "Recall: 0.7142857142857143\n",
      "F1: 0.6976744186046512\n",
      "ROC AUC: 0.6626984126984128\n",
      "Confusion Matrix:\n",
      "[[11  7]\n",
      " [ 6 15]]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3,\n",
    "                                                    random_state=4)\n",
    "# Doing 9 for my K, since I discovered thats the best one\n",
    "boi = knn.KNN(9, 'euclidian')\n",
    "boi.fit(x_train, y_train)\n",
    "preds = boi.predict(x_test)\n",
    "print_binary_classif_error_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvalid = pd.get_dummies(cvalid, columns=cat_features(cvalid))\n",
    "cvalid = cvalid.drop(['Churn_No'], axis=1)\n",
    "cvalid.rename(columns = {'Churn_Yes':'Churn'}, inplace = True)\n",
    "\n",
    "data_x = cvalid.drop(['Churn'], axis=1)\n",
    "data_y = cvalid['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46875\n",
      "Precison: 0.4090909090909091\n",
      "Recall: 0.6923076923076923\n",
      "F1: 0.5142857142857142\n",
      "ROC AUC: 0.5040485829959513\n",
      "Confusion Matrix:\n",
      "[[ 6 13]\n",
      " [ 4  9]]\n"
     ]
    }
   ],
   "source": [
    "preds2 = boi.predict(data_x)\n",
    "print_binary_classif_error_report(data_y, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The response variable is Churn, and the predictor variables are all other ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. I transformed the data by first doing OHE, then following that up by dropping churn_no and renaming churn_yes to just churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. I tried a couple models such as linear regression as well as both the sklearn and my KNN models. I found that mine worked a bit better, so I used it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I used the F1 from print_binary_classif_error_report to measure all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. I constructed my KNN using all predictors available and a K of 9, as that gave the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. I ran the validation through my KNN, and the error rates were worse than when run using the test set, but that was to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Somewhat. It could definitely be better, 50% definitely isn't good. I could've tried more models, but I'm unfortunately running out of time, and I'm very very tired."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
